<!DOCTYPE html>
<html>
<section class="section"><!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="TerraMind: Large-Scale Generative Multimodality for Earth Observation">
  <meta name="keywords" content="TerraMind, geospatial AI, multi-modality, foundation models">
  <meta name="author" content="IBM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TerraMind Blue-Sky Challenge</title>

  <!-- Fonts & CSS -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <!-- Light-gray background for every 2nd block -->
  <style>
    section.alt-bg:nth-of-type(odd){background:#f5f5f5;}
  </style>
</head>
<body>

<section class="hero is-medium is-parallax full-bleed hero-bg"
         style="background:url('./static/images/Blue sky image.png') center/cover no-repeat;">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
<!--      <h1 class="title is-1 white">TerraMind Blue-Sky Challenge</h1>-->
      <h1 class="title is-1 white">
        <img src="./static/images/boston.svg" alt="Logo" class="title-logo">
        TerraMind: Large-Scale Generative Multimodality for Earth Observation
      </h1>
      <br>
      <p class="subtitle is-5 has-text-weight-semibold white">organized by IBM and ESA</p>
      <!-- submit button -->
      <a href="https://huggingface.co/ibm-esa-geospatial" class="button is-link is-normal is-rounded is-dark">
        Try it out on HuggingFace!
      </a>
      <a href="https://arxiv.org/pdf/2504.11171" class="button is-link is-normal is-rounded is-dark">
        Find our arXiv preprint!
      </a>
      <a href="https://arxiv.org/pdf/2504.11172" class="button is-link is-normal is-rounded is-dark">
        Learn more about the TerraMesh dataset!
      </a>
    </div>
  </div>
</section>

<!-- â”€â”€â”€â”€â”€â”€â”€â”€â”€ INTRO â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

<section class="section alt-bg full-bleed intro-block">
  <div class="container is-max-desktop">
    <p class="intro">
      <strong>Meet TerraMind</strong>, the first any-to-any generative, multimodal foundation model for Earth observation. TerraMind represents new levels of understanding geospatial data, introduces new capabilities such as Thinking-in-Modalities (TiM), and outperforms existing models significantly across benchmarks like PANGAEA.
    </p>
  </div>
</section>

<!-- â”€â”€â”€â”€â”€â”€â”€â”€â”€ Architecture â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section class="section alt-bg full-bleed">
  <div class="container is-max-desktop">
    <h2 class="title is-3">ðŸ’¡ How does TerraMind work?</h2>
    <ul class="content">
      <img src="./static/images/terramind_architecture.png" alt="Logo" class="title-logo">
      <br>
      <p>TerraMind is pretrained on dual-scale representations combining both token-level and pixel-level data across modalities. On a token level, TerraMind encodes high-level contextual information to learn cross-modal relationships, while on a pixel level, TerraMind leverages fine-grained representations to capture critical spatial nuances.</p>
    </ul>
  </div>
</section>

<!-- â”€â”€â”€â”€â”€â”€â”€â”€â”€ TiM â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section class="section alt-bg full-bleed">
  <div class="container is-max-desktop">
    <h2 class="title is-3 mt-6">ðŸ’­What is Thinking-in-Modalities?</h2>
    <p>During fine-tuning or inference, TerraMind can pause for a moment, imagine a helpful but absent layer, append the imagined tokens to its own input sequence, and then lets the fine-tuned encoder continue to improve its own performance. Because the imagination lives in token space, we avoid the heavy diffusion decoding that full image synthesis would require. So, TerraMind can generate any missing modality as an intermediate step â€” an ability we call Thinking in Modalities (TiM).</p>
    <br>
    <img src="./static/images/tim.png" alt="Logo" class="title-logo">
  </div>
</section>

<!-- â”€â”€â”€â”€â”€â”€â”€â”€â”€ Benchmark performance â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section class="section alt-bg full-bleed">
  <div class="container is-max-desktop">
    <h2 class="title is-3">ðŸš€ How does TerraMind compare to other models?</h2>
    <img src="./static/images/performance.pdf" alt="Logo" class="title-logo">
    <br>
    TerraMind was benchmarked by ESA in both unimodal and multimodal settings following the community-standard PANGAEA benchmark. Overall, TerraMindv1-B outperforms all other GeoFMs by at least 3pp avg. mIoU. Importantly, TerraMind is the only foundation model approach in EO that outperforms task-specific U-Net models across the PANGAEA benchmark. Performance is approximately 2pp avg. mIoU higher for Terramindv1-L, with a peak of 5pp in multimodal datasets.
    <br>
    <img src="./static/images/full_comparison.png" alt="Logo" class="title-logo">
  </div>
</section>

<!-- â”€â”€â”€â”€â”€â”€â”€â”€â”€ SPARK & FAQ â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section class="section alt-bg full-bleed">
<!--  <p class="content has-text-centered">-->
<!--      <strong>Ready? Share your breakthrough and claim the next TerraMind Blue-Sky Award!</strong>-->
<!--  </p>-->

  <div class="container is-max-desktop">
    <h2 class="title is-5">Need a spark?</h2>
    <p class="content">
      Browse community ideas in the
      <a href="https://huggingface.co/spaces/ibm-esa-geospatial/community/discussions" target="_blank">Community</a>
      tab and leave a reaction if you like them.
    </p>

    <h2 class="title is-5 mt-6">Have a question?</h2>

    <p class="content">
      <strong>Where do I find more information on TerraMind?</strong><br>
      We provide details in our <a href="https://arxiv.org/abs/2504.11171" target="_blank">pre-print</a> and the model is available on <a href="https://huggingface.co/ibm-esa-geospatial/TerraMind-1.0-base" target="_blank">Hugging Face</a>.
    </p>

    <p class="content">
      <strong>Can I submit more than one idea?</strong><br>
      Yesâ€”submit as many innovations as you like, but remember that each team or individual can only win one round.
    </p>

    <p class="content">
    <strong>Do I have to open-source my code and data?</strong><br>
    Yes and no. It's not mandatory, but we value it in the spirit of open science and reproducibility during the evaluation.
    </p>

    <p class="content">
    <strong>Can I reuse work already published elsewhere?</strong><br>
    Yes, you should even link to the published work in your post.
    </p>

    <p class="content">
      <strong>Still unclear?</strong><br>
      Open a new discussion titled <code>[Question] topic</topic></code> in the Community tab.
    </p>
    <br>
  </div>
</section>

<!-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FOOTER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<footer class="footer full-bleed">
  <div class="container content has-text-centered">
    <p>Â© 2025 IBM & ESA â€“ TerraMind</p>
    <p>
      This site reuses elements from the
      <a href="https://github.com/nerfies/nerfies.github.io" target="_blank">Nerfies template</a>
      (CC-BY-SA 4.0).
    </p>
  </div>
</footer>
<script>
document.addEventListener('DOMContentLoaded', () => {
  const hero = document.querySelector('.hero-bg');
  if (!hero) return;                     // safety

  window.addEventListener('scroll', () => {
    const y = window.pageYOffset * 0.4;  // 0.2-0.5 = slower/faster
    hero.style.backgroundPosition = `center ${y}px`;
  });
});
</script>
</body>
</html>
</section>
</html>
