<!DOCTYPE html>
<html>
<section class="section"><!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="TerraMind: Large-Scale Generative Multimodality for Earth Observation">
  <meta name="keywords" content="TerraMind, geospatial AI, multi-modality, foundation models">
  <meta name="author" content="IBM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TerraMind Blue-Sky Challenge</title>

  <!-- Fonts & CSS -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico" type="image/x-icon">

  <!-- Light-gray background for every 2nd block -->
  <style>
    section.alt-bg:nth-of-type(odd){background:#f5f5f5;}
  </style>
</head>
<body>

<section class="hero is-medium is-parallax full-bleed hero-bg"
         style="background:url('./static/images/Blue sky image.png') center/cover no-repeat;">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
<!--      <h1 class="title is-1 white">TerraMind Blue-Sky Challenge</h1>-->
      <h1 class="title is-1 white">
        <img src="./static/images/terramind.png" alt="Logo" class="full-image">
        TerraMind: Large-Scale Generative Multimodality for Earth Observation
      </h1>
      <br>
      <p class="subtitle is-5 has-text-weight-semibold white">organized by IBM and ESA</p>
      <!-- submit button -->
      <a href="https://huggingface.co/ibm-esa-geospatial" class="button is-link is-normal is-rounded is-dark">
        Try it out on HuggingFace!
      </a>
      <a href="https://arxiv.org/pdf/2504.11171" class="button is-link is-normal is-rounded is-dark">
        Find our arXiv preprint!
      </a>
      <a href="https://arxiv.org/pdf/2504.11172" class="button is-link is-normal is-rounded is-dark">
        Learn more about the TerraMesh dataset!
      </a>
    </div>
  </div>
</section>

<!-- ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ INTRO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->

<section class="section alt-bg full-bleed intro-block">
  <div class="container is-max-desktop">
    <p class="intro">
      <strong>Meet TerraMind</strong>, the first any-to-any generative, multimodal foundation model for Earth observation. TerraMind represents new levels of understanding geospatial data, introduces new capabilities such as Thinking-in-Modalities (TiM), and outperforms existing models significantly across benchmarks like PANGAEA.
    </p>
  </div>
</section>

<!-- ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Architecture ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section class="section alt-bg full-bleed">
  <div class="container is-max-desktop">
    <h2 class="title is-3">üí° How does TerraMind work?</h2>
    <ul class="content">
      <img src="./static/images/terramind_architecture.png" alt="Architecture" class="full-image">
      <br>
      <p>TerraMind is pretrained on dual-scale representations combining both token-level and pixel-level data across modalities. On a token level, TerraMind encodes high-level contextual information to learn cross-modal relationships, while on a pixel level, TerraMind leverages fine-grained representations to capture critical spatial nuances.</p>
    </ul>
  </div>
</section>

<!-- ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TiM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section class="section alt-bg full-bleed">
  <div class="container is-max-desktop">
    <h2 class="title is-3 mt-6">üí≠ What is Thinking-in-Modalities?</h2>
    <p>During fine-tuning or inference, TerraMind can pause for a moment, imagine a helpful but absent layer, append the imagined tokens to its own input sequence, and then lets the fine-tuned encoder continue to improve its own performance. Because the imagination lives in token space, we avoid the heavy diffusion decoding that full image synthesis would require. So, TerraMind can generate any missing modality as an intermediate step ‚Äî an ability we call Thinking in Modalities (TiM).</p>
    <br>
    <img src="./static/images/tim.png" alt="TiM" class="full-image">
  </div>
</section>

<!-- ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Benchmark performance ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section class="section alt-bg full-bleed">
  <div class="container is-max-desktop">
    <h2 class="title is-3">üöÄ How does TerraMind compare to other models?</h2>
    <img src="./static/images/performance.pdf" alt="Radar Plot" class="full-image">
    <br>
    TerraMind was benchmarked by ESA in both unimodal and multimodal settings following the community-standard PANGAEA benchmark. Overall, TerraMindv1-B outperforms all other GeoFMs by at least 3pp avg. mIoU. Importantly, TerraMind is the only foundation model approach in EO that outperforms task-specific U-Net models across the PANGAEA benchmark. Performance is approximately 2pp avg. mIoU higher for Terramindv1-L, with a peak of 5pp in multimodal datasets.
    <br>
    <img src="./static/images/full_comparison.png" alt="Performance Table" class="full-image">
  </div>
</section>


<!-- ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Benchmark performance ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section class="section alt-bg full-bleed">
  <div class="container is-max-desktop">
    <h2 class="title is-3">üèÜ Need a challenge?</h2>
    <br>
    Find out more about our TerraMind Blue-Sky challenge here and the associated 1'000 EUR cash prizes.
    <br>
    <a href="https://huggingface.co/spaces/ibm-esa-geospatial/challenge" class="button is-link is-normal is-rounded is-dark">
        TerraMind Blue-Sky Challenge
    </a>
  </div>
</section>


<!-- ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ FOOTER ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<footer class="footer full-bleed">
  <div class="container content has-text-centered">
    <p>¬© 2025 IBM & ESA ‚Äì TerraMind</p>
    <p>
      This site reuses elements from the
      <a href="https://github.com/nerfies/nerfies.github.io" target="_blank">Nerfies template</a>
      (CC-BY-SA 4.0).
    </p>
  </div>
</footer>
<script>
document.addEventListener('DOMContentLoaded', () => {
  const hero = document.querySelector('.hero-bg');
  if (!hero) return;                     // safety

  window.addEventListener('scroll', () => {
    const y = window.pageYOffset * 0.4;  // 0.2-0.5 = slower/faster
    hero.style.backgroundPosition = `center ${y}px`;
  });
});
</script>
</body>
</html>
</section>
</html>
